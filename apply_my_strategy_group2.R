# setting the working directory if needed
setwd("C:\\Users\\erind\\Desktop\\drive-download-20211202T141140Z-001")

library(xts)
library(chron)
library(TTR)
library(knitr) # for nicely looking tables in html files
library(kableExtra) # for even more nicely looking tables in html files
library(quantmod) # for PnL graphs

# lets change the LC_TIME option to English
Sys.setlocale("LC_TIME", "English")

# mySR function
mySR <- function(x, scale) {
  sqrt(scale) * mean(coredata(x), na.rm = TRUE) / 
                sd(coredata(x), na.rm = TRUE)
  } 


# lets define the system time zone as America/New_York (used in the data)
Sys.setenv(TZ = 'America/New_York')

# do it simply in a loop on quarters

for (selected_quarter in c("2019_Q1","2019_Q2","2019_Q3", "2019_Q4", 
                           "2020_Q1","2020_Q2","2020_Q3","2020_Q4", 
                           "2021_Q1", "2021_Q2","2021_Q3","2021_Q4")) {
  
  message(selected_quarter)
  
  # loading the data for a selected quarter from a subdirectory "data""
  
  filename_ <- paste0("data/data2_", selected_quarter, ".RData")
  
  load(filename_)
  
  data.group2 <- get(paste0("data2_", selected_quarter))
  
  times_ <- substr(index(data.group2), 12, 19)
  
  # the following common assumptions were defined:
  # 1.	do not use in calculations the data from the first and last 10 minutes of the session (9:31--9:40 and 15:51--16:00) â€“ put missing values there,
  
  # lets put missing values ofr these periods
  data.group2["T09:31/T09:40",] <- NA 
  data.group2["T15:51/T16:00",] <- NA
  
  # lets calculate EMA10 and EMA60 for all series
  data.group2$AUD_EMA30 <- EMA(na.locf(data.group2$AUD), 30)
  data.group2$AUD_EMA120 <- EMA(na.locf(data.group2$AUD), 120)
  data.group2$CAD_EMA30 <- EMA(na.locf(data.group2$CAD), 30)
  data.group2$CAD_EMA120 <- EMA(na.locf(data.group2$CAD), 120)
  data.group2$XAG_EMA30 <- EMA(na.locf(data.group2$XAG), 30)
  data.group2$XAG_EMA120 <- EMA(na.locf(data.group2$XAG), 120)
  data.group2$XAU_EMA30 <- EMA(na.locf(data.group2$XAU), 30)
  data.group2$XAU_EMA120 <- EMA(na.locf(data.group2$XAU), 120)
  
  # put missing value whenever the original price is missing
  data.group2$AUD_EMA30[is.na(data.group2$AUD)] <- NA
  data.group2$AUD_EMA120[is.na(data.group2$AUD)] <- NA
  data.group2$CAD_EMA30[is.na(data.group2$CAD)] <- NA
  data.group2$CAD_EMA120[is.na(data.group2$CAD)] <- NA
  data.group2$XAG_EMA30[is.na(data.group2$XAG)] <- NA
  data.group2$XAG_EMA120[is.na(data.group2$XAG)] <- NA
  data.group2$XAU_EMA30[is.na(data.group2$XAU)] <- NA
  data.group2$XAU_EMA120[is.na(data.group2$XAU)] <- NA
  
  # lets calculate the position for the MOMENTUM strategy
  # for each asset separately
  # if fast MA(t-1) > slow MA(t-1) => pos(t) = 1 [long]
  # if fast MA(t-1) <= slow MA(t-1) => pos(t) = -1 [short]
  #  caution! this strategy is always in the market !
  
  data.group2$position.AUD.mom <- ifelse(lag.xts(data.group2$AUD_EMA30) >
                                          lag.xts(data.group2$AUD_EMA120),
                                        1, -1)
  
  data.group2$position.CAD.mom <- ifelse(lag.xts(data.group2$CAD_EMA30) >
                                            lag.xts(data.group2$CAD_EMA120),
                                          1, -1)
  
  data.group2$position.XAG.mom <- ifelse(lag.xts(data.group2$XAG_EMA30) >
                                            lag.xts(data.group2$XAG_EMA120),
                                          1, -1)
  
  data.group2$position.XAU.mom <- ifelse(lag.xts(data.group2$XAU_EMA30) >
                                           lag.xts(data.group2$XAU_EMA120),
                                         1, -1)
  
  
  # lets apply the remaining assumptions
  # - exit all positions 15 minutes before the session end, i.e. at 16:45
  # - do not trade within the first 15 minutes after the break (until 18:15)
  
  data.group2$position.AUD.mom[times(times_) > times("16:45:00") &
                                times(times_) <= times("18:15:00")] <- 0
  
  data.group2$position.CAD.mom[times(times_) > times("16:45:00") &
                                 times(times_) <= times("18:15:00")] <- 0
  
  data.group2$position.XAG.mom[times(times_) > times("16:45:00") &
                                 times(times_) <= times("18:15:00")] <- 0
  
  data.group2$position.XAU.mom[times(times_) > times("16:45:00") &
                                 times(times_) <= times("18:15:00")] <- 0
  
  
  # lets also fill every missing position with the previous one, our mean reverting strategy is the opposite of momentum strategy
  data.group2$position.AUD.mr <- -(na.locf(data.group2$position.AUD.mom, na.rm = FALSE))
  data.group2$position.CAD.mr <- -(na.locf(data.group2$position.CAD.mom, na.rm = FALSE))
  data.group2$position.XAG.mr <- -(na.locf(data.group2$position.XAG.mom, na.rm = FALSE))
  data.group2$position.XAU.mr <- -(na.locf(data.group2$position.XAU.mom, na.rm = FALSE))
  
  
  # calculating gross pnl - remember to multiply by the point value !!!!
  data.group2$pnl_gross.AUD.mr <- data.group2$position.AUD.mr * diff.xts(data.group2$AUD) * 100000
  data.group2$pnl_gross.CAD.mr <- data.group2$position.CAD.mr * diff.xts(data.group2$CAD) * 100000
  data.group2$pnl_gross.XAU.mr <- data.group2$position.XAU.mr * diff.xts(data.group2$XAU) * 100
  data.group2$pnl_gross.XAG.mr <- data.group2$position.XAG.mr * diff.xts(data.group2$XAG) * 5000
  
  # number of transactions
  
  data.group2$ntrans.AUD.mr <- abs(diff.xts(data.group2$position.AUD.mr))
  data.group2$ntrans.AUD.mr[1] <- 0
  
  data.group2$ntrans.CAD.mr <- abs(diff.xts(data.group2$position.CAD.mr))
  data.group2$ntrans.CAD.mr[1] <- 0
  
  data.group2$ntrans.XAG.mr <- abs(diff.xts(data.group2$position.XAG.mr))
  data.group2$ntrans.XAG.mr[1] <- 0
  
  data.group2$ntrans.XAU.mr <- abs(diff.xts(data.group2$position.XAU.mr))
  data.group2$ntrans.XAU.mr[1] <- 0
  
  # net pnl
  data.group2$pnl_net.AUD.mr <- data.group2$pnl_gross.AUD.mr  -
    data.group2$ntrans.AUD.mr * 5 # 5$ per transaction
  
  data.group2$pnl_net.CAD.mr <- data.group2$pnl_gross.CAD.mr  -
    data.group2$ntrans.CAD.mr * 5 # 5$ per transaction
  
  data.group2$pnl_net.XAG.mr <- data.group2$pnl_gross.XAG.mr  -
    data.group2$ntrans.XAG.mr * 5 # 5$ per transaction
    
  data.group2$pnl_net.XAU.mr <- data.group2$pnl_gross.XAU.mr  -
    data.group2$ntrans.XAU.mr * 10 # 10$ per transaction
  
  
  # aggregate pnls and number of transactions to daily
  my.endpoints <- endpoints(data.group2, "days")
  
  data.group2.daily <- period.apply(data.group2[,c(grep("pnl", names(data.group2)),
                                                   grep("ntrans", names(data.group2)))],
                                    INDEX = my.endpoints, 
                                    FUN = function(x) colSums(x, na.rm = TRUE))
  
  # lets SUM gross and net pnls
  
  data.group2.daily$pnl_gross.mr <- 
    data.group2.daily$pnl_gross.AUD.mr +
    data.group2.daily$pnl_gross.CAD.mr +
    data.group2.daily$pnl_gross.XAU.mr +
    data.group2.daily$pnl_gross.XAG.mr
  
  data.group2.daily$pnl_net.mr <- 
    data.group2.daily$pnl_net.AUD.mr +
    data.group2.daily$pnl_net.CAD.mr +
    data.group2.daily$pnl_net.XAU.mr +
    data.group2.daily$pnl_net.XAG.mr
  
  # lets SUM number of transactions (with the same weights)
  
  data.group2.daily$ntrans.mr <- 
    data.group2.daily$ntrans.AUD.mr +
    data.group2.daily$ntrans.CAD.mr +
    data.group2.daily$ntrans.XAG.mr +
    data.group2.daily$ntrans.XAU.mr
  
  
  # summarize the strategy for this quarter
  
  # SR
  grossSR = mySR(x = data.group2.daily$pnl_gross.mr, 
                 scale = 252)
  netSR = mySR(x = data.group2.daily$pnl_net.mr, 
               scale = 252)
  # average number of transactions
  av.daily.ntrades = mean(data.group2.daily$ntrans.mr, 
                          na.rm = TRUE)
  # PnL
  grossPnL = sum(data.group2.daily$pnl_gross.mr)
  netPnL = sum(data.group2.daily$pnl_net.mr)
  
  # stat
  stat = (netSR - 0.5) * max(0, log(abs(netPnL/1000)))
  
  # collecting all statistics for a particular quarter
  
  quarter_stats <- data.frame(quarter = selected_quarter,
                              assets.group = 2,
                              grossSR,
                              netSR,
                              av.daily.ntrades,
                              grossPnL,
                              netPnL,
                              stat,
                              stringsAsFactors = FALSE
  )
  
  # collect summaries for all quarters
  if(!exists("quarter_stats.all.group2")) quarter_stats.all.group2 <- quarter_stats else
    quarter_stats.all.group2 <- rbind(quarter_stats.all.group2, quarter_stats)
  
  # create a plot of gros and net pnl and save it to png file
  
  png(filename = paste0("pnl_group2_", selected_quarter, ".png"),
      width = 1000, height = 600)
  print( # when plotting in a loop you have to use print()
    plot(cbind(cumsum(data.group2.daily$pnl_gross.mr),
               cumsum(data.group2.daily$pnl_net.mr)),
         multi.panel = FALSE,
         main = paste0("Gross and net PnL for asset group 2 \n quarter ", selected_quarter), 
         col = c("#377EB8", "#E41A1C"),
         major.ticks = "weeks", 
         grid.ticks.on = "weeks",
         grid.ticks.lty = 3,
         legend.loc = "topleft",
         cex = 1)
  )
  dev.off()
  
  # remove all unneeded objects for group 2
  rm(data.group2, my.endpoints, grossSR, netSR, av.daily.ntrades,
     grossPnL, netPnL, stat, quarter_stats, data.group2.daily)
  
  gc()
  

} # end of the loop

write.csv(quarter_stats.all.group2, 
          "quarter_stats.all.group2.csv",
          row.names = FALSE)

